{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "id": "v8zJum2bt0dX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziy7Ncp8t3ow",
        "outputId": "5a711d83-2bc4-49a2-ca21-795a6a4eab85"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySrnmWlft0da"
      },
      "source": [
        "Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "Ec_L45Oft0dc"
      },
      "outputs": [],
      "source": [
        "image_rows, image_columns, image_depth = 64, 64, 96\n",
        "batch_size = 2\n",
        "epochs = 100\n",
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHwctjCwt0dc"
      },
      "source": [
        "Load your new dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "jazUFHB7t0dd"
      },
      "outputs": [],
      "source": [
        "data = []  # To store video data\n",
        "labels = []  # To store corresponding labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en2ioQO6t0dd"
      },
      "source": [
        "Modify this section to load your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "id": "nD6krwpKt0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981000ab-607c-42c9-88e3-ae47e3dcc1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Subject  ID  StartFrame  EndFrame                     VideoFile  \\\n",
            "0        1   1          52        65  european-poker-Barcelona.mp4   \n",
            "1        2   1          92       100  european-poker-Barcelona.mp4   \n",
            "2        2   2           7        35  european-poker-Barcelona.mp4   \n",
            "3        3   1          82        90  european-poker-Barcelona.mp4   \n",
            "4        4   1          18        29  european-poker-Barcelona.mp4   \n",
            "\n",
            "   StartFrameVideo  EndFrameVideo  Length   AU   Emotion  \\\n",
            "0            64967          64980      13  L12  contempt   \n",
            "1            11170          11172       2  R12  contempt   \n",
            "2            45910          45938      28  NaN       NaN   \n",
            "3            18683          18691       8  1.2  surprise   \n",
            "4            23317          23328      11  1.2  surprise   \n",
            "\n",
            "                               Note  \n",
            "0                               NaN  \n",
            "1                               NaN  \n",
            "2  smile, but not a microexpression  \n",
            "3                               NaN  \n",
            "4  more macro-expression, oclussion  \n"
          ]
        }
      ],
      "source": [
        "dataset_path = '/content/drive/MyDrive/VRN-Group-6/Dataset/me-cuts/cuts'  # Change this to the path of your dataset\n",
        "excel_file_path = '/content/drive/MyDrive/VRN-Group-6/Dataset/me-cuts/Micros_dataset.xls'\n",
        "class_folders = os.listdir(dataset_path)\n",
        "class_labels = {}  # Define a mapping of class labels to integers\n",
        "current_label = 0\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "data_frame = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Print the first few rows to verify the data\n",
        "print(data_frame.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample mapping between textual labels and numerical indices\n",
        "emotion_mapping = {\n",
        "    \"contempt\": 0,\n",
        "    \"smile\": 1,\n",
        "    \"surprise\": 2,\n",
        "    \"anger\": 3,\n",
        "    \"fear\": 4,\n",
        "    # Add more labels as needed\n",
        "}\n",
        "\n",
        "data_frame[\"Label\"] = data_frame[\"Emotion\"].map(emotion_mapping)\n",
        "\n",
        "# Replace NaN values with a default label (-1 in this example)\n",
        "data_frame[\"Label\"].fillna(-1, inplace=True)\n",
        "\n",
        "# Convert labels to integers\n",
        "data_frame[\"Label\"] = data_frame[\"Label\"].astype(int)\n",
        "\n",
        "# Check unique labels after the conversion\n",
        "unique_labels = data_frame[\"Label\"].unique()"
      ],
      "metadata": {
        "id": "Oz9kME3IJC3C"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "9lyGSkELt0de"
      },
      "outputs": [],
      "source": [
        "# Initialize data and labels lists\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for index, row in data_frame.iterrows():\n",
        "    subject = row['Subject']\n",
        "    id = row['ID']\n",
        "    start_frame = row['StartFrame']\n",
        "    end_frame = row['EndFrame']\n",
        "    emotion = row['Emotion']\n",
        "\n",
        "    if not pd.isna(emotion):  # Skip rows without emotion labels\n",
        "        # Check if the emotion label exists in the mapping; if not, assign a new label\n",
        "        if emotion not in class_labels:\n",
        "            class_labels[emotion] = len(class_labels)\n",
        "\n",
        "        class_label = class_labels[emotion]\n",
        "\n",
        "        video_file = f'sub{subject}-{id}.mp4'\n",
        "        video_path = os.path.join(dataset_path, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        video_frames = []  # To store frames of the current video\n",
        "\n",
        "        # Read frames within the specified range\n",
        "        for frame_number in range(start_frame, end_frame + 1):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame_resized = cv2.resize(frame, (image_columns, image_rows), interpolation=cv2.INTER_AREA)\n",
        "            gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
        "            gray_frame = gray_frame.astype('float32')  # Convert to float32\n",
        "            gray_frame -= np.mean(gray_frame)\n",
        "            max_value = np.max(gray_frame)\n",
        "            if max_value > 0:\n",
        "                gray_frame /= max_value\n",
        "            video_frames.append(gray_frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if len(video_frames) > 0:\n",
        "            # Append data and labels only when valid frames are available\n",
        "            data.append(video_frames)\n",
        "            labels.append(class_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "6rVf6oqUt0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ed5019-d858-496a-c2bc-f89fd20d80f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-388-ca3ee89e44c4>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = np.array(data)\n"
          ]
        }
      ],
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print(len(data))\n",
        "print(len(labels))\n",
        "# print(data)\n",
        "# print(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t34D-v7et0df"
      },
      "source": [
        "Convert labels to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "g-o_rfPOt0df"
      },
      "outputs": [],
      "source": [
        "# labels = to_categorical(data_frame[\"Label\"], num_classes=len(emotion_mapping))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVX_56ot0df"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "hvQajyYmt0dg"
      },
      "outputs": [],
      "source": [
        "# if data.size > 0:\n",
        "#     data = data.astype('float32')\n",
        "#     if np.max(data) > 0:\n",
        "#         data -= np.mean(data)\n",
        "#         data /= np.max(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljpa32mVt0dg"
      },
      "source": [
        "Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "NtHLn_Tpt0dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3e53d7-799a-44c6-ac53-9c0cbff11949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "13\n"
          ]
        }
      ],
      "source": [
        "# Split data into training and validation sets\n",
        "print(len(data))\n",
        "print(len(labels))\n",
        "\n",
        "max_frames = 78  # Set to a fixed maximum number of frames\n",
        "reshaped_data = np.zeros((len(data), image_rows, image_columns, max_frames))\n",
        "\n",
        "for i, video_frames in enumerate(data):\n",
        "    num_frames = len(video_frames)\n",
        "    frame_size = (image_columns, image_rows)  # Set the desired frame size\n",
        "\n",
        "    # Create an array to store the resized frames\n",
        "    resized_frames = np.zeros((num_frames, image_rows, image_columns))\n",
        "\n",
        "    for j, frame in enumerate(video_frames):\n",
        "        # Resize each frame to the desired size\n",
        "        resized_frame = cv2.resize(frame, frame_size, interpolation=cv2.INTER_AREA)\n",
        "        resized_frames[j, :, :] = resized_frame\n",
        "\n",
        "    if num_frames <= max_frames:\n",
        "        # If the number of frames is less than the maximum, pad the frames with zeros\n",
        "        reshaped_data[i, :, :, :num_frames] = np.moveaxis(resized_frames, 0, -1)\n",
        "    else:\n",
        "        # If the number of frames exceeds the maximum, truncate the frames\n",
        "        reshaped_data[i, :, :, :] = np.moveaxis(resized_frames[:max_frames], 0, -1)\n",
        "\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "labels = [label if 0 <= label < num_classes else num_classes - 1 for label in labels]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# # Now you can convert reshaped_data to TensorFlow tensors\n",
        "# train_data = tf.convert_to_tensor(reshaped_data, dtype=tf.float32)\n",
        "# train_labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "\n",
        "# train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "val_data = np.array(val_data)\n",
        "val_labels = np.array(val_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0O5czVt0dh"
      },
      "source": [
        "Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "SgWwvhsrt0dh"
      },
      "outputs": [],
      "source": [
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, (3, 3, 15), input_shape=(image_rows, image_columns, max_frames, 1), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN6flCttt0dh"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "id": "Q9fgZyUtt0dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc51276e-cee2-4790-b6c4-57fbbf54b17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "sgd = SGD(lr=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjGXQCWQt0dh"
      },
      "source": [
        "Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {
        "id": "RAuS6Rogt0dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d33c82-3395-49e9-9b7a-eb5f971c3ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_14 (Conv3D)          (None, 62, 62, 64, 32)    4352      \n",
            "                                                                 \n",
            " max_pooling3d_14 (MaxPooli  (None, 20, 20, 21, 32)    0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 20, 20, 21, 32)    0         \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 268800)            0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               34406528  \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34411525 (131.27 MB)\n",
            "Trainable params: 34411525 (131.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y23sQojGt0dh"
      },
      "source": [
        "Model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "id": "28lGQDFZt0di"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8rTbzllt0di"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "GK_CDgqjt0di",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "907dc08b-a7ee-4701-a75c-865f447081f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-400-f4dac3bce8b1>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train the model using the data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
          ]
        }
      ],
      "source": [
        "def data_generator(data, labels, batch_size):\n",
        "    num_samples = len(data)\n",
        "    while True:\n",
        "        indices = np.arange(num_samples)\n",
        "        np.random.shuffle(indices)\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            if len(batch_indices) < batch_size:  # Skip incomplete batches\n",
        "                continue\n",
        "            batch_data = [data[i] for i in batch_indices]  # Select data for the batch\n",
        "            batch_labels = [labels[i] for i in batch_indices]  # Select labels for the batch\n",
        "            yield np.array(batch_data), np.array(batch_labels)\n",
        "\n",
        "# Ensure the shape of train_data and val_data is (image_rows, image_columns, max_frames, 1)\n",
        "train_data = np.expand_dims(train_data, axis=-1)\n",
        "val_data = np.expand_dims(val_data, axis=-1)\n",
        "\n",
        "# Calculate the number of steps for training and validation\n",
        "train_steps = len(train_data) // batch_size\n",
        "val_steps = len(val_data) // batch_size\n",
        "\n",
        "# Train the model using the data generator\n",
        "model.fit(data_generator(train_data, train_labels, batch_size), steps_per_epoch=train_steps, validation_data=data_generator(val_data, val_labels, batch_size), validation_steps=val_steps, epochs=epochs, callbacks=callbacks_list)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}